# -*- coding: utf-8 -*-
"""plant_disease_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y_T4ywwx-AY5a0zOVUH407oNLKZp0T74
"""

import random
import numpy as np
import tensorflow as tf
#to stay standardized everytime i run the model
random.seed(0)
np.random.seed(0)
tf.random.set_seed(0)

import os
import json
from zipfile import ZipFile
from PIL import Image
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# i will be using plant village dataset to train this model
# !pip install kaggle

# accesing the kaggle file and converting it to a python dictionary
kaggleAccount=json.load(open('kaggle.json'))

# geeting kaggle creditentials
os.environ['KAGGLE_USERNAME']=kaggleAccount['username']
os.environ['KAGGLE_KEY']=kaggleAccount['key']

# downloading dataset
# !kaggle datasets download -d abdallahalidev/plantvillage-dataset

zipPath='plantvillage-dataset.zip'

try:
  if os.path.exists(zipPath):
    with ZipFile('plantvillage-dataset.zip','r') as zipObj:
        zipObj.extractall()
  else:
    print('dataset not found')
except Exception as e:
    print(e)

# getting a preview of the database
print(os.listdir('plantvillage dataset'))

print(len(os.listdir('plantvillage dataset/color')))
print(len(os.listdir('plantvillage dataset/segmented')))
print(len(os.listdir('plantvillage dataset/grayscale')))

print(os.listdir('plantvillage dataset/color')[:2])
print(os.listdir('plantvillage dataset/segmented')[:2])
print(os.listdir('plantvillage dataset/grayscale')[:2])

print(len(os.listdir("plantvillage dataset/color/Tomato___Leaf_Mold")))

baseDirectory= "plantvillage dataset/color"

imagePath='/content/plantvillage dataset/color/Tomato___Leaf_Mold/0160c3b5-d89e-40e5-a313-49ae1524040a___Crnl_L.Mold 6823.JPG'
img=mpimg.imread(imagePath)
print(img.shape)
plt.imshow(img)

# i will keep image size of 224 as most models are pretrained on such images
imgSize=224
batchSize=32

dataGenerator= ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
)

trainGenerator=dataGenerator.flow_from_directory(
    baseDirectory,
    target_size=(imgSize,imgSize),
    batch_size=batchSize,
    subset='training',
    class_mode='categorical',
)
validationGenerator=dataGenerator.flow_from_directory(
    baseDirectory,
    target_size=(imgSize,imgSize),
    batch_size=batchSize,
    subset='validation',
    class_mode='categorical',
)

model=models.Sequential()

model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(imgSize,imgSize,3)))
model.add(layers.MaxPooling2D(pool_size=(2,2)))

model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))

model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))

model.add(layers.Flatten())
model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(trainGenerator.num_classes,activation='softmax'))

model.summary()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history=model.fit(
    trainGenerator,
    steps_per_epoch=trainGenerator.samples//batchSize,
    epochs=2,
    validation_data=validationGenerator,
    validation_steps=validationGenerator.samples//batchSize,
)

oss, accu=model.evaluate(validationGenerator, steps=validationGenerator.samples//batchSize)
print(f"Accuracy: {accu*100:.2f}%")

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

def PreProcessImage(imagePath, targetSize=(224,224)):
  img=Image.open(imagePath)
  img=img.resize(targetSize)
  imgArray=np.array(img)
  imgArray=np.expand_dims(imgArray, axis=0)
  imgArray=imgArray.astype('float32')/255.0
  return imgArray

def predictImage(model, imgPath, classIndices):
  preprocessedImage=PreProcessImage(imgPath)
  prediction=model.predict(preprocessedImage)
  predictedClassIndex=np.argmax(prediction, axis=1)[0]
  predictClassName=classIndices[predictedClassIndex]
  return predictClassName

classIndices={v: k for k, v in trainGenerator.class_indices.items()}

classIndices

json.dump(classIndices, open('classIndices.json','w'))

model.save('/content/drive/MyDrive/plantVillageModel.h5')

imgPath='/content/plantvillage dataset/color/Blueberry___healthy/008c85d0-a954-4127-bd26-861dc8a1e6ff___RS_HL 2431.JPG'
predictClassName= predictImage(model, imgPath, classIndices)
print("Predicted class name: ",predictClassName)

